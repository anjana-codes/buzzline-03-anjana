2025-09-11 11:19:49,386 - DEBUG - Added sensor with name connections-closed
2025-09-11 11:19:49,386 - DEBUG - Added sensor with name connections-created
2025-09-11 11:19:49,386 - DEBUG - Added sensor with name select-time
2025-09-11 11:19:49,387 - DEBUG - Added sensor with name io-time
2025-09-11 11:19:49,387 - DEBUG - Attempting to check version with node bootstrap-0
2025-09-11 11:19:49,387 - DEBUG - Initiating connection to node bootstrap-0 at localhost:9092
2025-09-11 11:19:49,387 - DEBUG - Added sensor with name bytes-sent-received
2025-09-11 11:19:49,387 - DEBUG - Added sensor with name bytes-sent
2025-09-11 11:19:49,387 - DEBUG - Added sensor with name bytes-received
2025-09-11 11:19:49,388 - DEBUG - Added sensor with name request-latency
2025-09-11 11:19:49,389 - DEBUG - Added sensor with name throttle-time
2025-09-11 11:19:49,389 - DEBUG - Added sensor with name node-bootstrap-0.bytes-sent
2025-09-11 11:19:49,389 - DEBUG - Added sensor with name node-bootstrap-0.bytes-received
2025-09-11 11:19:49,389 - DEBUG - Added sensor with name node-bootstrap-0.latency
2025-09-11 11:19:49,389 - DEBUG - Added sensor with name node-bootstrap-0.throttle
2025-09-11 11:19:49,397 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=bootstrap-0 host=localhost:9092 <connecting> [unspecified None]>: creating new socket
2025-09-11 11:19:49,397 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: setting socket option (6, 1, 1)
2025-09-11 11:19:49,397 - INFO - <BrokerConnection client_id=kafka-python-2.2.15, node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2025-09-11 11:19:49,398 - DEBUG - Timeouts: user 200.000000, metadata inf, idle connection inf, request inf
2025-09-11 11:19:49,398 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: established TCP connection
2025-09-11 11:19:49,398 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=bootstrap-0 host=localhost:9092 <checking_api_versions_send> [IPv6 ('::1', 9092, 0, 0)]>: checking broker Api Versions
2025-09-11 11:19:49,398 - DEBUG - Sending request ApiVersionsRequest_v4(client_software_name='kafka-python', client_software_version='2.2.15', _tagged_fields={})
2025-09-11 11:19:49,398 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=bootstrap-0 host=localhost:9092 <checking_api_versions_send> [IPv6 ('::1', 9092, 0, 0)]>: Request 1 (timeout_ms 1000.0): ApiVersionsRequest_v4(client_software_name='kafka-python', client_software_version='2.2.15', _tagged_fields={})
2025-09-11 11:19:49,399 - DEBUG - Timeouts: user 200.000000, metadata inf, idle connection inf, request 1000.000000
2025-09-11 11:19:49,402 - DEBUG - Received correlation id: 1
2025-09-11 11:19:49,402 - DEBUG - Processing response ApiVersionsResponse_v4
2025-09-11 11:19:49,403 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=bootstrap-0 host=localhost:9092 <checking_api_versions_recv> [IPv6 ('::1', 9092, 0, 0)]>: Response 1 (4.004955291748047 ms): ApiVersionsResponse_v4(error_code=0, api_versions=[(api_key=0, min_version=0, max_version=11, _tagged_fields={}), (api_key=1, min_version=0, max_version=17, _tagged_fields={}), (api_key=2, min_version=0, max_version=9, _tagged_fields={}), (api_key=3, min_version=0, max_version=12, _tagged_fields={}), (api_key=8, min_version=0, max_version=9, _tagged_fields={}), (api_key=9, min_version=0, max_version=9, _tagged_fields={}), (api_key=10, min_version=0, max_version=6, _tagged_fields={}), (api_key=11, min_version=0, max_version=9, _tagged_fields={}), (api_key=12, min_version=0, max_version=4, _tagged_fields={}), (api_key=13, min_version=0, max_version=5, _tagged_fields={}), (api_key=14, min_version=0, max_version=5, _tagged_fields={}), (api_key=15, min_version=0, max_version=5, _tagged_fields={}), (api_key=16, min_version=0, max_version=5, _tagged_fields={}), (api_key=17, min_version=0, max_version=1, _tagged_fields={}), (api_key=18, min_version=0, max_version=4, _tagged_fields={}), (api_key=19, min_version=0, max_version=7, _tagged_fields={}), (api_key=20, min_version=0, max_version=6, _tagged_fields={}), (api_key=21, min_version=0, max_version=2, _tagged_fields={}), (api_key=22, min_version=0, max_version=5, _tagged_fields={}), (api_key=23, min_version=0, max_version=4, _tagged_fields={}), (api_key=24, min_version=0, max_version=5, _tagged_fields={}), (api_key=25, min_version=0, max_version=4, _tagged_fields={}), (api_key=26, min_version=0, max_version=4, _tagged_fields={}), (api_key=27, min_version=0, max_version=1, _tagged_fields={}), (api_key=28, min_version=0, max_version=4, _tagged_fields={}), (api_key=29, min_version=0, max_version=3, _tagged_fields={}), (api_key=30, min_version=0, max_version=3, _tagged_fields={}), (api_key=31, min_version=0, max_version=3, _tagged_fields={}), (api_key=32, min_version=0, max_version=4, _tagged_fields={}), (api_key=33, min_version=0, max_version=2, _tagged_fields={}), (api_key=34, min_version=0, max_version=2, _tagged_fields={}), (api_key=35, min_version=0, max_version=4, _tagged_fields={}), (api_key=36, min_version=0, max_version=2, _tagged_fields={}), (api_key=37, min_version=0, max_version=3, _tagged_fields={}), (api_key=38, min_version=0, max_version=3, _tagged_fields={}), (api_key=39, min_version=0, max_version=2, _tagged_fields={}), (api_key=40, min_version=0, max_version=2, _tagged_fields={}), (api_key=41, min_version=0, max_version=3, _tagged_fields={}), (api_key=42, min_version=0, max_version=2, _tagged_fields={}), (api_key=43, min_version=0, max_version=2, _tagged_fields={}), (api_key=44, min_version=0, max_version=1, _tagged_fields={}), (api_key=45, min_version=0, max_version=0, _tagged_fields={}), (api_key=46, min_version=0, max_version=0, _tagged_fields={}), (api_key=47, min_version=0, max_version=0, _tagged_fields={}), (api_key=48, min_version=0, max_version=1, _tagged_fields={}), (api_key=49, min_version=0, max_version=1, _tagged_fields={}), (api_key=50, min_version=0, max_version=0, _tagged_fields={}), (api_key=51, min_version=0, max_version=0, _tagged_fields={}), (api_key=55, min_version=0, max_version=2, _tagged_fields={}), (api_key=57, min_version=0, max_version=1, _tagged_fields={}), (api_key=60, min_version=0, max_version=1, _tagged_fields={}), (api_key=61, min_version=0, max_version=0, _tagged_fields={}), (api_key=64, min_version=0, max_version=0, _tagged_fields={}), (api_key=65, min_version=0, max_version=0, _tagged_fields={}), (api_key=66, min_version=0, max_version=1, _tagged_fields={}), (api_key=68, min_version=0, max_version=0, _tagged_fields={}), (api_key=69, min_version=0, max_version=0, _tagged_fields={}), (api_key=74, min_version=0, max_version=0, _tagged_fields={}), (api_key=75, min_version=0, max_version=0, _tagged_fields={}), (api_key=80, min_version=0, max_version=0, _tagged_fields={}), (api_key=81, min_version=0, max_version=0, _tagged_fields={})], throttle_time_ms=0, _tagged_fields={0: b'\x03\x0ekraft.version\x00\x00\x00\x01\x00\x11metadata.version\x00\x01\x00\x15\x00', 1: b'\x00\x00\x00\x00\x00\x00B\t', 2: b'\x02\x11metadata.version\x00\x15\x00\x15\x00'})
2025-09-11 11:19:49,404 - INFO - <BrokerConnection client_id=kafka-python-2.2.15, node_id=bootstrap-0 host=localhost:9092 <checking_api_versions_recv> [IPv6 ('::1', 9092, 0, 0)]>: Broker version identified as 2.6
2025-09-11 11:19:49,404 - INFO - <BrokerConnection client_id=kafka-python-2.2.15, node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2025-09-11 11:19:49,404 - DEBUG - Node bootstrap-0 connected
2025-09-11 11:19:49,404 - DEBUG - Added sensor with name bytes-fetched
2025-09-11 11:19:49,404 - DEBUG - Added sensor with name records-fetched
2025-09-11 11:19:49,404 - DEBUG - Added sensor with name fetch-latency
2025-09-11 11:19:49,405 - DEBUG - Added sensor with name records-lag
2025-09-11 11:19:49,405 - DEBUG - Added sensor with name heartbeat-latency
2025-09-11 11:19:49,405 - DEBUG - Added sensor with name join-latency
2025-09-11 11:19:49,405 - DEBUG - Added sensor with name sync-latency
2025-09-11 11:19:49,405 - DEBUG - Added sensor with name commit-latency
2025-09-11 11:19:49,405 - INFO - Updating subscribed topics to: ('anjana_csv_topic',)
2025-09-11 11:19:49,406 - DEBUG - Sending metadata request MetadataRequest_v7(topics=['anjana_csv_topic'], allow_auto_topic_creation=True) to node bootstrap-0
2025-09-11 11:19:49,406 - DEBUG - Sending request MetadataRequest_v7(topics=['anjana_csv_topic'], allow_auto_topic_creation=True)
2025-09-11 11:19:49,406 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 2 (timeout_ms 305000): MetadataRequest_v7(topics=['anjana_csv_topic'], allow_auto_topic_creation=True)
2025-09-11 11:19:49,406 - DEBUG - Requesting metadata for group coordinator request: NoBrokersAvailable
2025-09-11 11:19:49,406 - DEBUG - Timeouts: user inf, metadata 305000.000000, idle connection 539979.000000, request 305000.000000
2025-09-11 11:19:49,408 - DEBUG - Received correlation id: 2
2025-09-11 11:19:49,408 - DEBUG - Processing response MetadataResponse_v7
2025-09-11 11:19:49,408 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 2 (2.0186901092529297 ms): MetadataResponse_v7(throttle_time_ms=0, brokers=[(node_id=1, host='localhost', port=9092, rack=None)], cluster_id='Hd1Hmb7vSM2J7YUyp8I3Dw', controller_id=1, topics=[(error_code=0, topic='anjana_csv_topic', is_internal=False, partitions=[(error_code=0, partition=0, leader=1, leader_epoch=0, replicas=[1], isr=[1], offline_replicas=[])])])
2025-09-11 11:19:49,408 - DEBUG - Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 1, coordinators: 0)
2025-09-11 11:19:49,409 - DEBUG - Initiating connection to node 1 at localhost:9092
2025-09-11 11:19:49,409 - DEBUG - Added sensor with name node-1.bytes-sent
2025-09-11 11:19:49,409 - DEBUG - Added sensor with name node-1.bytes-received
2025-09-11 11:19:49,409 - DEBUG - Added sensor with name node-1.latency
2025-09-11 11:19:49,409 - DEBUG - Added sensor with name node-1.throttle
2025-09-11 11:19:49,410 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connecting> [unspecified None]>: creating new socket
2025-09-11 11:19:49,410 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: setting socket option (6, 1, 1)
2025-09-11 11:19:49,410 - INFO - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2025-09-11 11:19:49,411 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: established TCP connection
2025-09-11 11:19:49,411 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <checking_api_versions_send> [IPv6 ('::1', 9092, 0, 0)]>: checking broker Api Versions
2025-09-11 11:19:49,411 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <checking_api_versions_send> [IPv6 ('::1', 9092, 0, 0)]>: Using pre-configured api_version (2, 6) for ApiVersions
2025-09-11 11:19:49,411 - INFO - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2025-09-11 11:19:49,411 - DEBUG - Node 1 connected
2025-09-11 11:19:49,411 - INFO - <BrokerConnection client_id=kafka-python-2.2.15, node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2025-09-11 11:19:49,513 - DEBUG - Sending group coordinator request for group csv-group-anjana-loop to broker 1: FindCoordinatorRequest_v2(coordinator_key='csv-group-anjana-loop', coordinator_type=0)
2025-09-11 11:19:49,513 - DEBUG - Sending request FindCoordinatorRequest_v2(coordinator_key='csv-group-anjana-loop', coordinator_type=0)
2025-09-11 11:19:49,513 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 1 (timeout_ms 305000): FindCoordinatorRequest_v2(coordinator_key='csv-group-anjana-loop', coordinator_type=0)
2025-09-11 11:19:49,513 - DEBUG - Timeouts: user inf, metadata 299895.523438, idle connection 539873.000000, request 305000.000000
2025-09-11 11:19:49,513 - DEBUG - Timeouts: user inf, metadata 299895.523438, idle connection 539873.000000, request 305000.000000
2025-09-11 11:19:49,517 - DEBUG - Received correlation id: 1
2025-09-11 11:19:49,517 - DEBUG - Processing response FindCoordinatorResponse_v2
2025-09-11 11:19:49,517 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 1 (4.054546356201172 ms): FindCoordinatorResponse_v2(throttle_time_ms=0, error_code=0, error_message='NONE', coordinator_id=1, host='localhost', port=9092)
2025-09-11 11:19:49,517 - DEBUG - Received group coordinator response FindCoordinatorResponse_v2(throttle_time_ms=0, error_code=0, error_message='NONE', coordinator_id=1, host='localhost', port=9092)
2025-09-11 11:19:49,517 - DEBUG - Updating coordinator for group/csv-group-anjana-loop: FindCoordinatorResponse_v2(throttle_time_ms=0, error_code=0, error_message='NONE', coordinator_id=1, host='localhost', port=9092)
2025-09-11 11:19:49,517 - INFO - Coordinator for group/csv-group-anjana-loop is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9092, rack=None)
2025-09-11 11:19:49,517 - INFO - Discovered coordinator coordinator-1 for group csv-group-anjana-loop
2025-09-11 11:19:49,518 - INFO - Starting new heartbeat thread
2025-09-11 11:19:49,518 - DEBUG - Heartbeat thread started: <Heartbeat group_id=csv-group-anjana-loop heartbeat_interval_ms=3000 session_timeout_ms=10000 max_poll_interval_ms=300000 retry_backoff_ms=100>
2025-09-11 11:19:49,519 - DEBUG - Started heartbeat thread 14424
2025-09-11 11:19:49,519 - DEBUG - Heartbeat disabled. Waiting
2025-09-11 11:19:49,519 - INFO - Revoking previously assigned partitions set() for group csv-group-anjana-loop
2025-09-11 11:19:49,519 - DEBUG - Disabling heartbeat thread during join-group
2025-09-11 11:19:49,519 - DEBUG - Disabling heartbeat thread
2025-09-11 11:19:49,519 - INFO - Failed to join group csv-group-anjana-loop: NodeNotReadyError: coordinator-1
2025-09-11 11:19:49,519 - DEBUG - Initiating connection to node coordinator-1 at localhost:9092
2025-09-11 11:19:49,519 - DEBUG - Added sensor with name node-coordinator-1.bytes-sent
2025-09-11 11:19:49,519 - DEBUG - Added sensor with name node-coordinator-1.bytes-received
2025-09-11 11:19:49,519 - DEBUG - Added sensor with name node-coordinator-1.latency
2025-09-11 11:19:49,520 - DEBUG - Added sensor with name node-coordinator-1.throttle
2025-09-11 11:19:49,520 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connecting> [unspecified None]>: creating new socket
2025-09-11 11:19:49,520 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: setting socket option (6, 1, 1)
2025-09-11 11:19:49,520 - INFO - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2025-09-11 11:19:49,521 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: established TCP connection
2025-09-11 11:19:49,521 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <checking_api_versions_send> [IPv6 ('::1', 9092, 0, 0)]>: checking broker Api Versions
2025-09-11 11:19:49,521 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <checking_api_versions_send> [IPv6 ('::1', 9092, 0, 0)]>: Using pre-configured api_version (2, 6) for ApiVersions
2025-09-11 11:19:49,521 - INFO - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2025-09-11 11:19:49,521 - DEBUG - Node coordinator-1 connected
2025-09-11 11:19:49,623 - INFO - (Re-)joining group csv-group-anjana-loop
2025-09-11 11:19:49,623 - DEBUG - Sending JoinGroup (JoinGroupRequest_v4(group='csv-group-anjana-loop', session_timeout=10000, rebalance_timeout=300000, member_id='', protocol_type='consumer', group_protocols=[(protocol_name='range', protocol_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00'), (protocol_name='roundrobin', protocol_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00')])) to coordinator coordinator-1
2025-09-11 11:19:49,623 - DEBUG - Sending request JoinGroupRequest_v4(group='csv-group-anjana-loop', session_timeout=10000, rebalance_timeout=300000, member_id='', protocol_type='consumer', group_protocols=[(protocol_name='range', protocol_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00'), (protocol_name='roundrobin', protocol_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00')])
2025-09-11 11:19:49,623 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 1 (timeout_ms 305000): JoinGroupRequest_v4(group='csv-group-anjana-loop', session_timeout=10000, rebalance_timeout=300000, member_id='', protocol_type='consumer', group_protocols=[(protocol_name='range', protocol_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00'), (protocol_name='roundrobin', protocol_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00')])
2025-09-11 11:19:49,623 - DEBUG - Timeouts: user inf, metadata 299785.812744, idle connection 539763.000000, request 305000.000000
2025-09-11 11:19:49,624 - DEBUG - Timeouts: user inf, metadata 299784.801270, idle connection 539762.000000, request 304998.988390
2025-09-11 11:19:49,632 - DEBUG - Received correlation id: 1
2025-09-11 11:19:49,632 - DEBUG - Processing response JoinGroupResponse_v4
2025-09-11 11:19:49,632 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 1 (9.204864501953125 ms): JoinGroupResponse_v4(throttle_time_ms=0, error_code=79, generation_id=-1, group_protocol='', leader_id='', member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', members=[])
2025-09-11 11:19:49,632 - DEBUG - Received JoinGroup response: JoinGroupResponse_v4(throttle_time_ms=0, error_code=79, generation_id=-1, group_protocol='', leader_id='', member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', members=[])
2025-09-11 11:19:49,633 - INFO - Received member id kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840 for group csv-group-anjana-loop; will retry join-group
2025-09-11 11:19:49,633 - INFO - Failed to join group csv-group-anjana-loop: [Error 79] MemberIdRequiredError
2025-09-11 11:19:49,633 - INFO - (Re-)joining group csv-group-anjana-loop
2025-09-11 11:19:49,633 - DEBUG - Sending JoinGroup (JoinGroupRequest_v4(group='csv-group-anjana-loop', session_timeout=10000, rebalance_timeout=300000, member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', protocol_type='consumer', group_protocols=[(protocol_name='range', protocol_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00'), (protocol_name='roundrobin', protocol_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00')])) to coordinator coordinator-1
2025-09-11 11:19:49,633 - DEBUG - Sending request JoinGroupRequest_v4(group='csv-group-anjana-loop', session_timeout=10000, rebalance_timeout=300000, member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', protocol_type='consumer', group_protocols=[(protocol_name='range', protocol_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00'), (protocol_name='roundrobin', protocol_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00')])
2025-09-11 11:19:49,633 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 2 (timeout_ms 305000): JoinGroupRequest_v4(group='csv-group-anjana-loop', session_timeout=10000, rebalance_timeout=300000, member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', protocol_type='consumer', group_protocols=[(protocol_name='range', protocol_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00'), (protocol_name='roundrobin', protocol_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00')])
2025-09-11 11:19:49,633 - DEBUG - Timeouts: user inf, metadata 299775.548096, idle connection 539753.000000, request 305000.000000
2025-09-11 11:19:49,634 - DEBUG - Timeouts: user inf, metadata 299775.548096, idle connection 539753.000000, request 305000.000000
2025-09-11 11:19:52,369 - DEBUG - Received correlation id: 2
2025-09-11 11:19:52,369 - DEBUG - Processing response JoinGroupResponse_v4
2025-09-11 11:19:52,369 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 2 (2736.1953258514404 ms): JoinGroupResponse_v4(throttle_time_ms=0, error_code=0, generation_id=1, group_protocol='range', leader_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', members=[(member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', member_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00')])
2025-09-11 11:19:52,369 - DEBUG - Received JoinGroup response: JoinGroupResponse_v4(throttle_time_ms=0, error_code=0, generation_id=1, group_protocol='range', leader_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', members=[(member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', member_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x00')])
2025-09-11 11:19:52,370 - INFO - Successfully joined group csv-group-anjana-loop <Generation 1 (member_id: kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840, protocol: range)>
2025-09-11 11:19:52,370 - INFO - Elected group leader -- performing partition assignments using range
2025-09-11 11:19:52,370 - DEBUG - Performing assignment for group csv-group-anjana-loop using strategy range with subscriptions {'kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840': ConsumerProtocolMemberMetadata(version=0, subscription=['anjana_csv_topic'], user_data=b'')}
2025-09-11 11:19:52,370 - DEBUG - Finished assignment for group csv-group-anjana-loop: {'kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840': ConsumerProtocolMemberAssignment(version=0, assignment=[(topic='anjana_csv_topic', partitions=[0])], user_data=b'')}
2025-09-11 11:19:52,370 - DEBUG - Sending leader SyncGroup for group csv-group-anjana-loop to coordinator coordinator-1: SyncGroupRequest_v2(group='csv-group-anjana-loop', generation_id=1, member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', group_assignment=[(member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', member_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00')])
2025-09-11 11:19:52,370 - DEBUG - Sending request SyncGroupRequest_v2(group='csv-group-anjana-loop', generation_id=1, member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', group_assignment=[(member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', member_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00')])
2025-09-11 11:19:52,370 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 3 (timeout_ms 305000): SyncGroupRequest_v2(group='csv-group-anjana-loop', generation_id=1, member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', group_assignment=[(member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', member_metadata=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00')])
2025-09-11 11:19:52,370 - DEBUG - Sending metadata request MetadataRequest_v7(topics=['anjana_csv_topic'], allow_auto_topic_creation=True) to node 1
2025-09-11 11:19:52,371 - DEBUG - Sending request MetadataRequest_v7(topics=['anjana_csv_topic'], allow_auto_topic_creation=True)
2025-09-11 11:19:52,371 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 2 (timeout_ms 305000): MetadataRequest_v7(topics=['anjana_csv_topic'], allow_auto_topic_creation=True)
2025-09-11 11:19:52,371 - DEBUG - Timeouts: user inf, metadata 305000.000000, idle connection 537015.000000, request 304999.000549
2025-09-11 11:19:52,371 - DEBUG - Timeouts: user inf, metadata 305000.000000, idle connection 537015.000000, request 304999.000549
2025-09-11 11:19:52,372 - DEBUG - Received correlation id: 2
2025-09-11 11:19:52,372 - DEBUG - Processing response MetadataResponse_v7
2025-09-11 11:19:52,372 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 2 (1.0001659393310547 ms): MetadataResponse_v7(throttle_time_ms=0, brokers=[(node_id=1, host='localhost', port=9092, rack=None)], cluster_id='Hd1Hmb7vSM2J7YUyp8I3Dw', controller_id=1, topics=[(error_code=0, topic='anjana_csv_topic', is_internal=False, partitions=[(error_code=0, partition=0, leader=1, leader_epoch=0, replicas=[1], isr=[1], offline_replicas=[])])])
2025-09-11 11:19:52,373 - DEBUG - Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 1, coordinators: 1)
2025-09-11 11:19:52,373 - DEBUG - Timeouts: user inf, metadata 300000.000000, idle connection 537013.000000, request 304997.003794
2025-09-11 11:19:52,378 - DEBUG - Received correlation id: 3
2025-09-11 11:19:52,378 - DEBUG - Processing response SyncGroupResponse_v2
2025-09-11 11:19:52,378 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 3 (7.997035980224609 ms): SyncGroupResponse_v2(throttle_time_ms=0, error_code=0, member_assignment=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00')
2025-09-11 11:19:52,378 - DEBUG - Received SyncGroup response: SyncGroupResponse_v2(throttle_time_ms=0, error_code=0, member_assignment=b'\x00\x00\x00\x00\x00\x01\x00\x10anjana_csv_topic\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00')
2025-09-11 11:19:52,379 - DEBUG - Enabling heartbeat thread
2025-09-11 11:19:52,379 - INFO - Updated partition assignment: [TopicPartition(topic='anjana_csv_topic', partition=0)]
2025-09-11 11:19:52,379 - INFO - Setting newly assigned partitions {TopicPartition(topic='anjana_csv_topic', partition=0)} for group csv-group-anjana-loop
2025-09-11 11:19:52,379 - DEBUG - Group csv-group-anjana-loop fetching committed offsets for partitions: {TopicPartition(topic='anjana_csv_topic', partition=0)}
2025-09-11 11:19:52,379 - DEBUG - Sending request OffsetFetchRequest_v5(consumer_group='csv-group-anjana-loop', topics=[(topic='anjana_csv_topic', partitions=[0])])
2025-09-11 11:19:52,379 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 4 (timeout_ms 305000): OffsetFetchRequest_v5(consumer_group='csv-group-anjana-loop', topics=[(topic='anjana_csv_topic', partitions=[0])])
2025-09-11 11:19:52,380 - DEBUG - Heartbeat re-enabled.
2025-09-11 11:19:52,380 - DEBUG - Timeouts: user 0.000000, metadata 299992.968750, idle connection 537006.000000, request 304999.002218
2025-09-11 11:19:52,380 - DEBUG - Waiting 3.0 secs to send next heartbeat
2025-09-11 11:19:52,380 - DEBUG - Timeouts: user inf, metadata 299992.968750, idle connection 537006.000000, request 304999.002218
2025-09-11 11:19:52,383 - DEBUG - Received correlation id: 4
2025-09-11 11:19:52,383 - DEBUG - Processing response OffsetFetchResponse_v5
2025-09-11 11:19:52,384 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 4 (4.965782165527344 ms): OffsetFetchResponse_v5(throttle_time_ms=0, topics=[(topic='anjana_csv_topic', partitions=[(partition=0, offset=-1, leader_epoch=-1, metadata='', error_code=0)])], error_code=0)
2025-09-11 11:19:52,384 - DEBUG - Received OffsetFetchResponse: OffsetFetchResponse_v5(throttle_time_ms=0, topics=[(topic='anjana_csv_topic', partitions=[(partition=0, offset=-1, leader_epoch=-1, metadata='', error_code=0)])], error_code=0)
2025-09-11 11:19:52,384 - DEBUG - Group csv-group-anjana-loop has no committed offset for partition TopicPartition(topic='anjana_csv_topic', partition=0)
2025-09-11 11:19:52,384 - DEBUG - Resetting offsets for {TopicPartition(topic='anjana_csv_topic', partition=0)}
2025-09-11 11:19:52,384 - DEBUG - Sending ListOffsetRequest ListOffsetsRequest_v4(replica_id=-1, isolation_level=0, topics=[(topic='anjana_csv_topic', partitions=[(partition=0, current_leader_epoch=-1, timestamp=-2)])]) to broker 1
2025-09-11 11:19:52,384 - DEBUG - Sending request ListOffsetsRequest_v4(replica_id=-1, isolation_level=0, topics=[(topic='anjana_csv_topic', partitions=[(partition=0, current_leader_epoch=-1, timestamp=-2)])])
2025-09-11 11:19:52,384 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 3 (timeout_ms 305000): ListOffsetsRequest_v4(replica_id=-1, isolation_level=0, topics=[(topic='anjana_csv_topic', partitions=[(partition=0, current_leader_epoch=-1, timestamp=-2)])])
2025-09-11 11:19:52,385 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:52,385 - DEBUG - poll: Sending fetches
2025-09-11 11:19:52,385 - DEBUG - poll: do not have all fetch positions...
2025-09-11 11:19:52,385 - DEBUG - Timeouts: user 99.000000, metadata 299988.001221, idle connection 537001.000000, request 304999.000549
2025-09-11 11:19:52,385 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:52,385 - DEBUG - poll: Sending fetches
2025-09-11 11:19:52,385 - DEBUG - Timeouts: user 2994.000000, metadata 299988.001221, idle connection 537001.000000, request 304999.000549
2025-09-11 11:19:52,393 - DEBUG - Received correlation id: 3
2025-09-11 11:19:52,393 - DEBUG - Processing response ListOffsetsResponse_v4
2025-09-11 11:19:52,393 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 3 (9.007453918457031 ms): ListOffsetsResponse_v4(throttle_time_ms=0, topics=[(topic='anjana_csv_topic', partitions=[(partition=0, error_code=0, timestamp=-1, offset=0, leader_epoch=0)])])
2025-09-11 11:19:52,393 - DEBUG - Handling ListOffsetsResponse response for TopicPartition(topic='anjana_csv_topic', partition=0). Fetched offset 0, timestamp -1, leader_epoch 0
2025-09-11 11:19:52,393 - INFO - Resetting offset for partition TopicPartition(topic='anjana_csv_topic', partition=0) to offset 0.
2025-09-11 11:19:52,393 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:52,393 - DEBUG - poll: Sending fetches
2025-09-11 11:19:52,394 - DEBUG - Adding fetch request for partition TopicPartition(topic='anjana_csv_topic', partition=0) at offset 0
2025-09-11 11:19:52,394 - DEBUG - Built full fetch <kafka.consumer.fetcher.FetchMetadata object at 0x0000021B158B5F00> for node 1 with 1 partition(s).
2025-09-11 11:19:52,394 - DEBUG - Sending FetchRequest to node 1
2025-09-11 11:19:52,394 - DEBUG - Sending request FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=0, session_epoch=0, topics=[(topic='anjana_csv_topic', partitions=[(partition=0, current_leader_epoch=-1, fetch_offset=0, log_start_offset=-1, max_bytes=1048576)])], forgotten_topics_data=[])
2025-09-11 11:19:52,394 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 4 (timeout_ms 305000): FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=0, session_epoch=0, topics=[(topic='anjana_csv_topic', partitions=[(partition=0, current_leader_epoch=-1, fetch_offset=0, log_start_offset=-1, max_bytes=1048576)])], forgotten_topics_data=[])
2025-09-11 11:19:52,394 - DEBUG - Timeouts: user 0.000000, metadata 299978.968750, idle connection 536992.000000, request 305000.000000
2025-09-11 11:19:52,395 - DEBUG - Timeouts: user 2984.000000, metadata 299977.999023, idle connection 536991.000000, request 304999.030113
2025-09-11 11:19:52,403 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:52,403 - DEBUG - poll: Sending fetches
2025-09-11 11:19:52,403 - DEBUG - Skipping fetch for partition TopicPartition(topic='anjana_csv_topic', partition=0) because there is a pending fetch request to node 1
2025-09-11 11:19:52,403 - DEBUG - Timeouts: user 2976.000000, metadata 299970.000732, idle connection 536983.000000, request 304991.031885
2025-09-11 11:19:52,403 - DEBUG - Received correlation id: 4
2025-09-11 11:19:52,403 - DEBUG - Processing response FetchResponse_v10
2025-09-11 11:19:52,404 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 4 (9.967803955078125 ms): FetchResponse_v10(throttle_time_ms=0, error_code=0, session_id=1348344455, topics=[(topics='anjana_csv_topic', partitions=[(partition=0, error_code=0, highwater_offset=22, last_stable_offset=22, log_start_offset=0, aborted_transactions=NULL, records=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02m\xd66O\x00\x00\x00\x00\x00\x00\x00\x00\x01\x999S\xdb\xeb\x00\x00\x01\x999S\xdb\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01r{"timestamp": "2025-01-01 15:00:0...')])])
2025-09-11 11:19:52,404 - DEBUG - Node 1 sent a full fetch response that created a new incremental fetch session 1348344455 with 1 response partitions
2025-09-11 11:19:52,404 - DEBUG - Preparing to read 2750 bytes of data for partition TopicPartition(topic='anjana_csv_topic', partition=0) with offset 0
2025-09-11 11:19:52,404 - DEBUG - Returning fetched records at offset 0 for assigned partition TopicPartition(topic='anjana_csv_topic', partition=0)
2025-09-11 11:19:52,406 - DEBUG - Added sensor with name topic.anjana_csv_topic.bytes-fetched
2025-09-11 11:19:52,406 - DEBUG - Added sensor with name topic.anjana_csv_topic.records-fetched
2025-09-11 11:19:52,406 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:00:00', 'temperature': 70.4}
2025-09-11 11:19:52,406 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:01:00', 'temperature': 70.8}
2025-09-11 11:19:52,406 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:02:00', 'temperature': 71.2}
2025-09-11 11:19:52,432 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:03:00', 'temperature': 71.5}
2025-09-11 11:19:52,433 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:00:00', 'temperature': 70.4}
2025-09-11 11:19:52,433 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:01:00', 'temperature': 70.8}
2025-09-11 11:19:52,439 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:02:00', 'temperature': 71.2}
2025-09-11 11:19:52,439 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:03:00', 'temperature': 71.5}
2025-09-11 11:19:52,439 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:00:00', 'temperature': 70.4}
2025-09-11 11:19:52,448 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:01:00', 'temperature': 70.8}
2025-09-11 11:19:52,448 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:02:00', 'temperature': 71.2}
2025-09-11 11:19:52,448 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:03:00', 'temperature': 71.5}
2025-09-11 11:19:52,459 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:00:00', 'temperature': 70.4}
2025-09-11 11:19:52,459 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:01:00', 'temperature': 70.8}
2025-09-11 11:19:52,459 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:00:00', 'temperature': 70.4}
2025-09-11 11:19:52,475 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:01:00', 'temperature': 70.8}
2025-09-11 11:19:52,475 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:02:00', 'temperature': 71.2}
2025-09-11 11:19:52,476 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:03:00', 'temperature': 71.5}
2025-09-11 11:19:52,489 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:00:00', 'temperature': 70.4}
2025-09-11 11:19:52,489 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:01:00', 'temperature': 70.8}
2025-09-11 11:19:52,489 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:02:00', 'temperature': 71.2}
2025-09-11 11:19:52,500 - DEBUG - Consumed CSV message: {'timestamp': '2025-01-01 15:03:00', 'temperature': 71.5}
2025-09-11 11:19:52,501 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:52,501 - DEBUG - poll: Sending fetches
2025-09-11 11:19:52,501 - DEBUG - Adding fetch request for partition TopicPartition(topic='anjana_csv_topic', partition=0) at offset 22
2025-09-11 11:19:52,502 - DEBUG - Building incremental partitions from next: {TopicPartition(topic='anjana_csv_topic', partition=0)}, previous: {TopicPartition(topic='anjana_csv_topic', partition=0)}
2025-09-11 11:19:52,502 - DEBUG - Built incremental fetch <kafka.consumer.fetcher.FetchMetadata object at 0x0000021B1E4BD600> for node 1. Added set(), altered {TopicPartition(topic='anjana_csv_topic', partition=0)}, removed set() out of odict_keys([TopicPartition(topic='anjana_csv_topic', partition=0)])
2025-09-11 11:19:52,502 - DEBUG - Sending FetchRequest to node 1
2025-09-11 11:19:52,502 - DEBUG - Sending request FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=1, topics=[(topic='anjana_csv_topic', partitions=[(partition=0, current_leader_epoch=-1, fetch_offset=22, log_start_offset=-1, max_bytes=1048576)])], forgotten_topics_data=[])
2025-09-11 11:19:52,502 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 5 (timeout_ms 305000): FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=1, topics=[(topic='anjana_csv_topic', partitions=[(partition=0, current_leader_epoch=-1, fetch_offset=22, log_start_offset=-1, max_bytes=1048576)])], forgotten_topics_data=[])
2025-09-11 11:19:52,504 - DEBUG - Timeouts: user 0.000000, metadata 299868.996582, idle connection 536882.000000, request 304998.998404
2025-09-11 11:19:52,505 - DEBUG - Timeouts: user 2874.000000, metadata 299867.994141, idle connection 536881.000000, request 304997.995853
2025-09-11 11:19:52,964 - DEBUG - Received correlation id: 5
2025-09-11 11:19:52,964 - DEBUG - Processing response FetchResponse_v10
2025-09-11 11:19:52,964 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 5 (460.9997272491455 ms): FetchResponse_v10(throttle_time_ms=0, error_code=0, session_id=1348344455, topics=[])
2025-09-11 11:19:52,964 - DEBUG - Node 1 sent an incremental fetch response for session 1348344455 with 0 response partitions (1 implied)
2025-09-11 11:19:52,964 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:52,964 - DEBUG - poll: Sending fetches
2025-09-11 11:19:52,964 - DEBUG - Adding fetch request for partition TopicPartition(topic='anjana_csv_topic', partition=0) at offset 22
2025-09-11 11:19:52,964 - DEBUG - Building incremental partitions from next: {TopicPartition(topic='anjana_csv_topic', partition=0)}, previous: {TopicPartition(topic='anjana_csv_topic', partition=0)}
2025-09-11 11:19:52,964 - DEBUG - Built incremental fetch <kafka.consumer.fetcher.FetchMetadata object at 0x0000021B1E4BD450> for node 1. Added set(), altered set(), removed set() out of odict_keys([TopicPartition(topic='anjana_csv_topic', partition=0)])
2025-09-11 11:19:52,964 - DEBUG - Sending FetchRequest to node 1
2025-09-11 11:19:52,964 - DEBUG - Sending request FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=2, topics=[], forgotten_topics_data=[])
2025-09-11 11:19:52,965 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 6 (timeout_ms 305000): FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=2, topics=[], forgotten_topics_data=[])
2025-09-11 11:19:52,965 - DEBUG - Timeouts: user 0.000000, metadata 299407.970215, idle connection 536421.000000, request 305000.000000
2025-09-11 11:19:52,965 - DEBUG - Timeouts: user 2414.000000, metadata 299407.970215, idle connection 536421.000000, request 305000.000000
2025-09-11 11:19:53,422 - DEBUG - Received correlation id: 6
2025-09-11 11:19:53,422 - DEBUG - Processing response FetchResponse_v10
2025-09-11 11:19:53,422 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 6 (457.3338031768799 ms): FetchResponse_v10(throttle_time_ms=0, error_code=0, session_id=1348344455, topics=[])
2025-09-11 11:19:53,423 - DEBUG - Node 1 sent an incremental fetch response for session 1348344455 with 0 response partitions (1 implied)
2025-09-11 11:19:53,423 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:53,423 - DEBUG - poll: Sending fetches
2025-09-11 11:19:53,423 - DEBUG - Adding fetch request for partition TopicPartition(topic='anjana_csv_topic', partition=0) at offset 22
2025-09-11 11:19:53,423 - DEBUG - Building incremental partitions from next: {TopicPartition(topic='anjana_csv_topic', partition=0)}, previous: {TopicPartition(topic='anjana_csv_topic', partition=0)}
2025-09-11 11:19:53,423 - DEBUG - Built incremental fetch <kafka.consumer.fetcher.FetchMetadata object at 0x0000021B1E4BD5D0> for node 1. Added set(), altered set(), removed set() out of odict_keys([TopicPartition(topic='anjana_csv_topic', partition=0)])
2025-09-11 11:19:53,423 - DEBUG - Sending FetchRequest to node 1
2025-09-11 11:19:53,423 - DEBUG - Sending request FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=3, topics=[], forgotten_topics_data=[])
2025-09-11 11:19:53,423 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 7 (timeout_ms 305000): FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=3, topics=[], forgotten_topics_data=[])
2025-09-11 11:19:53,423 - DEBUG - Timeouts: user 0.000000, metadata 298949.617188, idle connection 535962.000000, request 305000.000000
2025-09-11 11:19:53,424 - DEBUG - Timeouts: user 1955.000000, metadata 298949.617188, idle connection 535962.000000, request 305000.000000
2025-09-11 11:19:53,882 - DEBUG - Received correlation id: 7
2025-09-11 11:19:53,882 - DEBUG - Processing response FetchResponse_v10
2025-09-11 11:19:53,882 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 7 (459.0940475463867 ms): FetchResponse_v10(throttle_time_ms=0, error_code=0, session_id=1348344455, topics=[])
2025-09-11 11:19:53,882 - DEBUG - Node 1 sent an incremental fetch response for session 1348344455 with 0 response partitions (1 implied)
2025-09-11 11:19:53,882 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:53,882 - DEBUG - poll: Sending fetches
2025-09-11 11:19:53,882 - DEBUG - Adding fetch request for partition TopicPartition(topic='anjana_csv_topic', partition=0) at offset 22
2025-09-11 11:19:53,882 - DEBUG - Building incremental partitions from next: {TopicPartition(topic='anjana_csv_topic', partition=0)}, previous: {TopicPartition(topic='anjana_csv_topic', partition=0)}
2025-09-11 11:19:53,884 - DEBUG - Built incremental fetch <kafka.consumer.fetcher.FetchMetadata object at 0x0000021B1E4BD600> for node 1. Added set(), altered set(), removed set() out of odict_keys([TopicPartition(topic='anjana_csv_topic', partition=0)])
2025-09-11 11:19:53,884 - DEBUG - Sending FetchRequest to node 1
2025-09-11 11:19:53,884 - DEBUG - Sending request FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=4, topics=[], forgotten_topics_data=[])
2025-09-11 11:19:53,884 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 8 (timeout_ms 305000): FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=4, topics=[], forgotten_topics_data=[])
2025-09-11 11:19:53,884 - DEBUG - Timeouts: user 0.000000, metadata 298489.499512, idle connection 535502.000000, request 305000.000000
2025-09-11 11:19:53,884 - DEBUG - Timeouts: user 1495.000000, metadata 298489.499512, idle connection 535502.000000, request 305000.000000
2025-09-11 11:19:54,341 - DEBUG - Received correlation id: 8
2025-09-11 11:19:54,341 - DEBUG - Processing response FetchResponse_v10
2025-09-11 11:19:54,341 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 8 (457.0629596710205 ms): FetchResponse_v10(throttle_time_ms=0, error_code=0, session_id=1348344455, topics=[])
2025-09-11 11:19:54,341 - DEBUG - Node 1 sent an incremental fetch response for session 1348344455 with 0 response partitions (1 implied)
2025-09-11 11:19:54,342 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:54,342 - DEBUG - poll: Sending fetches
2025-09-11 11:19:54,342 - DEBUG - Adding fetch request for partition TopicPartition(topic='anjana_csv_topic', partition=0) at offset 22
2025-09-11 11:19:54,342 - DEBUG - Building incremental partitions from next: {TopicPartition(topic='anjana_csv_topic', partition=0)}, previous: {TopicPartition(topic='anjana_csv_topic', partition=0)}
2025-09-11 11:19:54,342 - DEBUG - Built incremental fetch <kafka.consumer.fetcher.FetchMetadata object at 0x0000021B1E4BD450> for node 1. Added set(), altered set(), removed set() out of odict_keys([TopicPartition(topic='anjana_csv_topic', partition=0)])
2025-09-11 11:19:54,342 - DEBUG - Sending FetchRequest to node 1
2025-09-11 11:19:54,342 - DEBUG - Sending request FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=5, topics=[], forgotten_topics_data=[])
2025-09-11 11:19:54,342 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 9 (timeout_ms 305000): FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=5, topics=[], forgotten_topics_data=[])
2025-09-11 11:19:54,343 - DEBUG - Timeouts: user 0.000000, metadata 298031.436523, idle connection 535044.000000, request 305000.000000
2025-09-11 11:19:54,343 - DEBUG - Timeouts: user 1036.000000, metadata 298030.446777, idle connection 535043.000000, request 304999.010086
2025-09-11 11:19:54,801 - DEBUG - Received correlation id: 9
2025-09-11 11:19:54,801 - DEBUG - Processing response FetchResponse_v10
2025-09-11 11:19:54,801 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 9 (458.99200439453125 ms): FetchResponse_v10(throttle_time_ms=0, error_code=0, session_id=1348344455, topics=[])
2025-09-11 11:19:54,801 - DEBUG - Node 1 sent an incremental fetch response for session 1348344455 with 0 response partitions (1 implied)
2025-09-11 11:19:54,801 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:54,801 - DEBUG - poll: Sending fetches
2025-09-11 11:19:54,801 - DEBUG - Adding fetch request for partition TopicPartition(topic='anjana_csv_topic', partition=0) at offset 22
2025-09-11 11:19:54,801 - DEBUG - Building incremental partitions from next: {TopicPartition(topic='anjana_csv_topic', partition=0)}, previous: {TopicPartition(topic='anjana_csv_topic', partition=0)}
2025-09-11 11:19:54,801 - DEBUG - Built incremental fetch <kafka.consumer.fetcher.FetchMetadata object at 0x0000021B1E4BD5D0> for node 1. Added set(), altered set(), removed set() out of odict_keys([TopicPartition(topic='anjana_csv_topic', partition=0)])
2025-09-11 11:19:54,802 - DEBUG - Sending FetchRequest to node 1
2025-09-11 11:19:54,802 - DEBUG - Sending request FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=6, topics=[], forgotten_topics_data=[])
2025-09-11 11:19:54,802 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 10 (timeout_ms 305000): FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=6, topics=[], forgotten_topics_data=[])
2025-09-11 11:19:54,802 - DEBUG - Timeouts: user 0.000000, metadata 297571.430176, idle connection 534584.000000, request 305000.000000
2025-09-11 11:19:54,802 - DEBUG - Timeouts: user 577.000000, metadata 297571.430176, idle connection 534584.000000, request 305000.000000
2025-09-11 11:19:55,258 - DEBUG - Received correlation id: 10
2025-09-11 11:19:55,258 - DEBUG - Processing response FetchResponse_v10
2025-09-11 11:19:55,258 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 10 (456.4487934112549 ms): FetchResponse_v10(throttle_time_ms=0, error_code=0, session_id=1348344455, topics=[])
2025-09-11 11:19:55,259 - DEBUG - Node 1 sent an incremental fetch response for session 1348344455 with 0 response partitions (1 implied)
2025-09-11 11:19:55,259 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:55,259 - DEBUG - poll: Sending fetches
2025-09-11 11:19:55,259 - DEBUG - Adding fetch request for partition TopicPartition(topic='anjana_csv_topic', partition=0) at offset 22
2025-09-11 11:19:55,259 - DEBUG - Building incremental partitions from next: {TopicPartition(topic='anjana_csv_topic', partition=0)}, previous: {TopicPartition(topic='anjana_csv_topic', partition=0)}
2025-09-11 11:19:55,259 - DEBUG - Built incremental fetch <kafka.consumer.fetcher.FetchMetadata object at 0x0000021B1E4BD600> for node 1. Added set(), altered set(), removed set() out of odict_keys([TopicPartition(topic='anjana_csv_topic', partition=0)])
2025-09-11 11:19:55,259 - DEBUG - Sending FetchRequest to node 1
2025-09-11 11:19:55,259 - DEBUG - Sending request FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=7, topics=[], forgotten_topics_data=[])
2025-09-11 11:19:55,259 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 11 (timeout_ms 305000): FetchRequest_v10(replica_id=-1, max_wait_time=500, min_bytes=1, max_bytes=52428800, isolation_level=0, session_id=1348344455, session_epoch=7, topics=[], forgotten_topics_data=[])
2025-09-11 11:19:55,260 - DEBUG - Timeouts: user 0.000000, metadata 297112.975098, idle connection 534126.000000, request 305000.000000
2025-09-11 11:19:55,260 - DEBUG - Timeouts: user 119.000000, metadata 297112.975098, idle connection 534126.000000, request 305000.000000
2025-09-11 11:19:55,382 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:55,382 - DEBUG - Timeouts: user 0.000000, metadata 296990.604492, idle connection 534003.000000, request 304877.629519
2025-09-11 11:19:55,382 - DEBUG - poll: Sending fetches
2025-09-11 11:19:55,383 - DEBUG - Skipping fetch for partition TopicPartition(topic='anjana_csv_topic', partition=0) because there is a pending fetch request to node 1
2025-09-11 11:19:55,383 - DEBUG - Sending heartbeat for group csv-group-anjana-loop <Generation 1 (member_id: kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840, protocol: range)>
2025-09-11 11:19:55,383 - DEBUG - Sending HeartbeatRequest to coordinator-1: HeartbeatRequest_v2(group='csv-group-anjana-loop', generation_id=1, member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840')
2025-09-11 11:19:55,383 - DEBUG - Sending request HeartbeatRequest_v2(group='csv-group-anjana-loop', generation_id=1, member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840')
2025-09-11 11:19:55,383 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 5 (timeout_ms 305000): HeartbeatRequest_v2(group='csv-group-anjana-loop', generation_id=1, member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840')
2025-09-11 11:19:55,384 - DEBUG - Timeouts: user 0.000000, metadata 296988.597900, idle connection 534001.000000, request 304875.622749
2025-09-11 11:19:55,384 - DEBUG - Waiting 3.0 secs to send next heartbeat
2025-09-11 11:19:55,384 - DEBUG - Timeouts: user 1995.000000, metadata 296988.597900, idle connection 534001.000000, request 304875.622749
2025-09-11 11:19:55,386 - DEBUG - Received correlation id: 5
2025-09-11 11:19:55,386 - DEBUG - Processing response HeartbeatResponse_v2
2025-09-11 11:19:55,386 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 5 (2.8524398803710938 ms): HeartbeatResponse_v2(throttle_time_ms=0, error_code=0)
2025-09-11 11:19:55,386 - DEBUG - Received heartbeat response for group csv-group-anjana-loop: HeartbeatResponse_v2(throttle_time_ms=0, error_code=0)
2025-09-11 11:19:55,386 - DEBUG - Heartbeat success
2025-09-11 11:19:55,386 - DEBUG - poll: fetched records: {}, False
2025-09-11 11:19:55,386 - DEBUG - poll: Sending fetches
2025-09-11 11:19:55,386 - DEBUG - Skipping fetch for partition TopicPartition(topic='anjana_csv_topic', partition=0) because there is a pending fetch request to node 1
2025-09-11 11:19:55,386 - DEBUG - Timeouts: user 1992.000000, metadata 296986.744141, idle connection 534000.000000, request 304873.769045
2025-09-11 11:19:55,716 - WARNING - Consumer interrupted by user.
2025-09-11 11:19:55,716 - DEBUG - Closing the KafkaConsumer.
2025-09-11 11:19:55,716 - DEBUG - Sending offset-commit request with {TopicPartition(topic='anjana_csv_topic', partition=0): OffsetAndMetadata(offset=22, metadata='', leader_epoch=-1)} for group csv-group-anjana-loop to coordinator-1
2025-09-11 11:19:55,716 - DEBUG - Sending request OffsetCommitRequest_v6(consumer_group='csv-group-anjana-loop', consumer_group_generation_id=1, consumer_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', topics=[(topic='anjana_csv_topic', partitions=[(partition=0, offset=22, leader_epoch=-1, metadata='')])])
2025-09-11 11:19:55,717 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 6 (timeout_ms 305000): OffsetCommitRequest_v6(consumer_group='csv-group-anjana-loop', consumer_group_generation_id=1, consumer_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840', topics=[(topic='anjana_csv_topic', partitions=[(partition=0, offset=22, leader_epoch=-1, metadata='')])])
2025-09-11 11:19:55,717 - DEBUG - Timeouts: user 305000.000000, metadata 296655.573242, idle connection 533668.000000, request 304542.598248
2025-09-11 11:19:55,717 - DEBUG - Received correlation id: 11
2025-09-11 11:19:55,717 - DEBUG - Processing response FetchResponse_v10
2025-09-11 11:19:55,717 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 11 (457.4017524719238 ms): FetchResponse_v10(throttle_time_ms=0, error_code=0, session_id=1348344455, topics=[])
2025-09-11 11:19:55,717 - DEBUG - Node 1 sent an incremental fetch response for session 1348344455 with 0 response partitions (1 implied)
2025-09-11 11:19:55,718 - DEBUG - Timeouts: user 305000.000000, metadata 296654.566650, idle connection 533667.000000, request 304998.993397
2025-09-11 11:19:55,722 - DEBUG - Received correlation id: 6
2025-09-11 11:19:55,723 - DEBUG - Processing response OffsetCommitResponse_v6
2025-09-11 11:19:55,723 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 6 (6.021022796630859 ms): OffsetCommitResponse_v6(throttle_time_ms=0, topics=[(topic='anjana_csv_topic', partitions=[(partition=0, error_code=0)])])
2025-09-11 11:19:55,723 - DEBUG - Received OffsetCommitResponse: OffsetCommitResponse_v6(throttle_time_ms=0, topics=[(topic='anjana_csv_topic', partitions=[(partition=0, error_code=0)])])
2025-09-11 11:19:55,723 - DEBUG - Group csv-group-anjana-loop committed offset OffsetAndMetadata(offset=22, metadata='', leader_epoch=-1) for partition TopicPartition(topic='anjana_csv_topic', partition=0)
2025-09-11 11:19:55,723 - INFO - Stopping heartbeat thread
2025-09-11 11:19:55,723 - DEBUG - Heartbeat thread closed
2025-09-11 11:19:55,723 - INFO - Leaving consumer group (csv-group-anjana-loop).
2025-09-11 11:19:55,724 - DEBUG - Sending LeaveGroupRequest to coordinator-1: LeaveGroupRequest_v2(group='csv-group-anjana-loop', member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840')
2025-09-11 11:19:55,724 - DEBUG - Sending request LeaveGroupRequest_v2(group='csv-group-anjana-loop', member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840')
2025-09-11 11:19:55,724 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Request 7 (timeout_ms 305000): LeaveGroupRequest_v2(group='csv-group-anjana-loop', member_id='kafka-python-2.2.15-2c50d075-af77-44ae-98a5-fb8fc8652840')
2025-09-11 11:19:55,724 - DEBUG - Timeouts: user 305000.000000, metadata 296648.587158, idle connection 533661.000000, request 305000.000000
2025-09-11 11:19:55,724 - DEBUG - Timeouts: user 305000.000000, metadata 296648.587158, idle connection 533661.000000, request 305000.000000
2025-09-11 11:19:55,730 - DEBUG - Received correlation id: 7
2025-09-11 11:19:55,730 - DEBUG - Processing response LeaveGroupResponse_v2
2025-09-11 11:19:55,730 - DEBUG - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Response 7 (6.003379821777344 ms): LeaveGroupResponse_v2(throttle_time_ms=0, error_code=0)
2025-09-11 11:19:55,731 - DEBUG - Received LeaveGroupResponse: LeaveGroupResponse_v2(throttle_time_ms=0, error_code=0)
2025-09-11 11:19:55,731 - INFO - LeaveGroup request for group csv-group-anjana-loop returned successfully
2025-09-11 11:19:55,731 - INFO - <BrokerConnection client_id=kafka-python-2.2.15, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2025-09-11 11:19:55,731 - INFO - <BrokerConnection client_id=kafka-python-2.2.15, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2025-09-11 11:19:55,732 - DEBUG - The KafkaConsumer has closed.
2025-09-11 11:19:55,732 - INFO - Kafka consumer closed.
